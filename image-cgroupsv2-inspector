#!/usr/bin/env python3.12
"""
image-cgroupsv2-inspector
=========================

A tool to inspect container images in an OpenShift cluster for cgroups v2 compatibility.

This tool connects to an OpenShift cluster, collects information about all container
images running in pods, deployments, statefulsets, daemonsets, jobs, and cronjobs,
and saves the information to a CSV file.

Usage:
    ./image-cgroupsv2-inspector --api-url <URL> --token <TOKEN> [--rootfs-path <PATH>]
    ./image-cgroupsv2-inspector  # Uses credentials from .env file

Author: Amedeo
License: See LICENSE file
"""

import argparse
import sys
import os
import logging
from pathlib import Path

# Add src directory to path
script_dir = Path(__file__).parent.resolve()
sys.path.insert(0, str(script_dir))

from src.openshift_client import OpenShiftClient
from src.image_collector import ImageCollector
from src.rootfs_manager import RootFSManager
from src.system_checks import run_system_checks


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        prog="image-cgroupsv2-inspector",
        description="Inspect container images in an OpenShift cluster for cgroups v2 compatibility",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Connect with API URL and token
  ./image-cgroupsv2-inspector --api-url https://api.mycluster.example.com:6443 --token <token>

  # Use credentials from .env file
  ./image-cgroupsv2-inspector

  # Specify rootfs path for image extraction
  ./image-cgroupsv2-inspector --rootfs-path /tmp/images

Environment Variables:
  OPENSHIFT_API_URL    OpenShift API URL
  OPENSHIFT_TOKEN      Bearer token for authentication

The tool will save credentials to .env file after successful connection.
        """
    )

    parser.add_argument(
        "--api-url",
        dest="api_url",
        type=str,
        help="OpenShift API URL (e.g., https://api.mycluster.example.com:6443)"
    )

    parser.add_argument(
        "--token",
        dest="token",
        type=str,
        help="Bearer token for OpenShift authentication"
    )

    parser.add_argument(
        "--rootfs-path",
        dest="rootfs_path",
        type=str,
        help="Path where rootfs directory will be created for image extraction"
    )

    parser.add_argument(
        "--output-dir",
        dest="output_dir",
        type=str,
        default="output",
        help="Directory to save CSV output (default: output)"
    )

    parser.add_argument(
        "--env-file",
        dest="env_file",
        type=str,
        default=".env",
        help="Path to .env file for credentials (default: .env)"
    )

    parser.add_argument(
        "--verify-ssl",
        dest="verify_ssl",
        action="store_true",
        default=False,
        help="Verify SSL certificates (default: False)"
    )

    parser.add_argument(
        "--skip-collection",
        dest="skip_collection",
        action="store_true",
        default=False,
        help="Skip image collection (useful for testing rootfs setup)"
    )

    parser.add_argument(
        "--analyze",
        dest="analyze",
        action="store_true",
        default=False,
        help="Analyze images for Java/NodeJS/.NET binaries (requires --rootfs-path)"
    )

    parser.add_argument(
        "--pull-secret",
        dest="pull_secret",
        type=str,
        default=".pull-secret",
        help="Path to pull-secret file for image authentication (default: .pull-secret)"
    )

    parser.add_argument(
        "-n", "--namespace",
        dest="namespace",
        type=str,
        help="Only inspect images in the specified namespace. "
             "If not provided, all namespaces are inspected (except those excluded by --exclude-namespaces)."
    )

    parser.add_argument(
        "--exclude-namespaces",
        dest="exclude_namespaces",
        type=str,
        default="openshift-*,kube-*",
        help="Comma-separated list of namespace patterns to exclude. "
             "Supports glob patterns with * (e.g., 'openshift-*,kube-*'). "
             "Default: 'openshift-*,kube-*'. "
             "Ignored when --namespace is specified."
    )

    parser.add_argument(
        "-v", "--verbose",
        dest="verbose",
        action="store_true",
        default=False,
        help="Enable verbose output"
    )

    parser.add_argument(
        "--log-to-file",
        dest="log_to_file",
        action="store_true",
        default=False,
        help="Enable logging to file"
    )

    parser.add_argument(
        "--log-file",
        dest="log_file",
        type=str,
        default="image-cgroupsv2-inspector.log",
        help="Path to log file (default: image-cgroupsv2-inspector.log). Implies --log-to-file"
    )

    parser.add_argument(
        "--version",
        action="version",
        version="%(prog)s 1.0.0"
    )

    return parser.parse_args()


def setup_logging(log_to_file: bool, log_file: str, verbose: bool) -> logging.Logger:
    """
    Set up logging configuration.
    
    Args:
        log_to_file: Whether to enable file logging.
        log_file: Path to the log file.
        verbose: Whether to enable verbose (DEBUG) logging.
    
    Returns:
        Configured logger instance.
    """
    logger = logging.getLogger("image-cgroupsv2-inspector")
    logger.setLevel(logging.DEBUG if verbose else logging.INFO)
    
    # Log format
    log_format = logging.Formatter(
        "%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    
    if log_to_file:
        # File handler
        file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG if verbose else logging.INFO)
        file_handler.setFormatter(log_format)
        logger.addHandler(file_handler)
        print(f"ðŸ“ Logging to file: {log_file}")
    
    return logger


def print_banner():
    """Print the application banner."""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           image-cgroupsv2-inspector v1.0.0                   â•‘
â•‘     OpenShift Container Image Inspector for cgroups v2       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def setup_rootfs(rootfs_path: str, logger: logging.Logger = None) -> bool:
    """
    Set up the rootfs directory with proper permissions and ACLs.

    Args:
        rootfs_path: Path where rootfs directory will be created.
        logger: Logger instance for file logging.

    Returns:
        True if successful, False otherwise.
    """
    print(f"\nðŸ”§ Setting up rootfs directory at: {rootfs_path}")
    if logger:
        logger.info(f"Setting up rootfs directory at: {rootfs_path}")
    
    manager = RootFSManager(rootfs_path)
    
    # Create rootfs directory with ACLs (includes validation)
    success, msg = manager.create_rootfs_directory()
    if not success:
        print(f"âœ— Failed to create rootfs: {msg}")
        if logger:
            logger.error(f"Failed to create rootfs: {msg}")
        return False
    
    print(f"\nâœ“ {msg}")
    if logger:
        logger.info(f"Rootfs setup successful: {msg}")
    return True


def main() -> int:
    """Main entry point."""
    print_banner()
    
    # Parse arguments
    args = parse_arguments()
    
    # Change to script directory for relative paths
    os.chdir(script_dir)
    
    # Set up logging
    # If --log-file is specified with a non-default value, imply --log-to-file
    log_to_file = args.log_to_file or args.log_file != "image-cgroupsv2-inspector.log"
    logger = setup_logging(log_to_file, args.log_file, args.verbose)
    
    if log_to_file:
        logger.info("=" * 60)
        logger.info("image-cgroupsv2-inspector started")
        logger.info("=" * 60)
    
    # Run system checks (podman, etc.)
    if log_to_file:
        logger.info("Running system checks...")
    if not run_system_checks(verbose=args.verbose):
        print("\nâœ— System checks failed. Please install the required dependencies.")
        if log_to_file:
            logger.error("System checks failed")
        return 1
    if log_to_file:
        logger.info("System checks passed")
    
    # Handle rootfs path if provided
    if args.rootfs_path:
        if not setup_rootfs(args.rootfs_path, logger if log_to_file else None):
            return 1
        
        if args.skip_collection:
            print("\nâœ“ Rootfs setup complete. Skipping image collection.")
            if log_to_file:
                logger.info("Rootfs setup complete. Skipping image collection.")
            return 0
    
    # Create OpenShift client
    try:
        if log_to_file:
            logger.info("Creating OpenShift client...")
        client = OpenShiftClient(
            api_url=args.api_url,
            token=args.token,
            env_file=args.env_file,
            verify_ssl=args.verify_ssl
        )
        
        # Check if we have credentials
        if not client.api_url or not client.token:
            print("\nâœ— Error: OpenShift credentials not provided.")
            print("  Please provide --api-url and --token, or set them in .env file.")
            print("\n  To get a token, run: oc whoami -t")
            print("  To get the API URL, run: oc whoami --show-server")
            if log_to_file:
                logger.error("OpenShift credentials not provided")
            return 1
        
        # Connect to the cluster
        print("\nðŸ”Œ Connecting to OpenShift cluster...")
        if log_to_file:
            logger.info(f"Connecting to OpenShift cluster at {client.api_url}")
        client.connect()
        if log_to_file:
            logger.info(f"Connected successfully to cluster: {client.cluster_name}")
        
    except ValueError as e:
        print(f"\nâœ— Configuration error: {e}")
        if log_to_file:
            logger.error(f"Configuration error: {e}")
        return 1
    except Exception as e:
        print(f"\nâœ— Connection error: {e}")
        if log_to_file:
            logger.error(f"Connection error: {e}")
        return 1
    
    try:
        # Handle namespace filtering
        if args.namespace:
            # Single namespace mode - ignore exclusion patterns
            print(f"\nðŸ“‹ Inspecting single namespace: {args.namespace}")
            if log_to_file:
                logger.info(f"Inspecting single namespace: {args.namespace}")
            collector = ImageCollector(client, namespace=args.namespace)
        else:
            # All namespaces mode - apply exclusion patterns
            exclude_patterns = None
            if args.exclude_namespaces:
                exclude_patterns = [p.strip() for p in args.exclude_namespaces.split(",") if p.strip()]
                print(f"\nðŸ“‹ Namespace exclusion patterns: {', '.join(exclude_patterns)}")
                if log_to_file:
                    logger.info(f"Namespace exclusion patterns: {', '.join(exclude_patterns)}")
            collector = ImageCollector(client, exclude_namespace_patterns=exclude_patterns)
        
        # Collect images
        if log_to_file:
            logger.info("Collecting container images from cluster...")
        total = collector.collect_all()
        if log_to_file:
            logger.info(f"Collected {total} containers")
        
        if total == 0:
            print("\nâš  No containers found in the cluster.")
            if log_to_file:
                logger.warning("No containers found in the cluster")
            return 0
        
        # Analyze images if requested
        if args.analyze:
            if not args.rootfs_path:
                print("\nâœ— Error: --analyze requires --rootfs-path to be specified.")
                if log_to_file:
                    logger.error("--analyze requires --rootfs-path to be specified")
                return 1
            
            # Check if pull-secret exists
            pull_secret_path = None
            if args.pull_secret and Path(args.pull_secret).exists():
                pull_secret_path = args.pull_secret
                print(f"\nðŸ”‘ Using pull-secret: {pull_secret_path}")
                if log_to_file:
                    logger.info(f"Using pull-secret: {pull_secret_path}")
            else:
                print("\nâš  Warning: No pull-secret found. Some images may fail to pull.")
                if log_to_file:
                    logger.warning("No pull-secret found. Some images may fail to pull.")
            
            # Get the rootfs path
            manager = RootFSManager(args.rootfs_path)
            rootfs_path = str(manager.get_rootfs_path().parent)
            
            # Check for internal registry route (needed to pull internal images)
            internal_registry_route = client.get_internal_registry_route()
            if internal_registry_route:
                if log_to_file:
                    logger.info(f"Internal registry route: {internal_registry_route}")
            
            # Analyze images (saves CSV after each image for resumability)
            if log_to_file:
                logger.info("Starting image analysis...")
            _, csv_path = collector.analyze_images(
                rootfs_path, 
                pull_secret_path, 
                debug=args.verbose,
                cluster_name=client.cluster_name,
                output_dir=args.output_dir,
                logger=logger if log_to_file else None,
                internal_registry_route=internal_registry_route,
                openshift_token=client.token
            )
            if log_to_file:
                logger.info("Image analysis completed")
        else:
            # Save to CSV (only if not analyzing - analysis saves incrementally)
            csv_path = collector.save_to_csv(
                cluster_name=client.cluster_name,
                output_dir=args.output_dir
            )
            if log_to_file:
                logger.info(f"Results saved to CSV: {csv_path}")
        
        # Show summary
        df = collector.to_dataframe()
        unique_images = collector.get_unique_images()
        
        print("\nðŸ“Š Summary:")
        print(f"   Total containers: {len(df)}")
        print(f"   Unique images: {len(unique_images)}")
        print(f"   Namespaces: {df['namespace'].nunique()}")
        print(f"   Object types: {df['object_type'].value_counts().to_dict()}")
        
        # Show analysis summary if analysis was performed
        if args.analyze:
            java_found = df[df['java_binary'] != 'None']['java_binary'].count()
            node_found = df[df['node_binary'] != 'None']['node_binary'].count()
            dotnet_found = df[df['dotnet_binary'] != 'None']['dotnet_binary'].count()
            java_compat = df[df['java_cgroup_v2_compatible'] == 'Yes'].shape[0]
            java_incompat = df[df['java_cgroup_v2_compatible'] == 'No'].shape[0]
            node_compat = df[df['node_cgroup_v2_compatible'] == 'Yes'].shape[0]
            node_incompat = df[df['node_cgroup_v2_compatible'] == 'No'].shape[0]
            dotnet_compat = df[df['dotnet_cgroup_v2_compatible'] == 'Yes'].shape[0]
            dotnet_incompat = df[df['dotnet_cgroup_v2_compatible'] == 'No'].shape[0]
            
            print(f"\n   ðŸ”¬ Analysis Results:")
            print(f"      Java found in: {java_found} containers")
            if java_found > 0:
                print(f"        âœ“ cgroup v2 compatible: {java_compat}")
                print(f"        âœ— cgroup v2 incompatible: {java_incompat}")
            print(f"      Node.js found in: {node_found} containers")
            if node_found > 0:
                print(f"        âœ“ cgroup v2 compatible: {node_compat}")
                print(f"        âœ— cgroup v2 incompatible: {node_incompat}")
            print(f"      .NET found in: {dotnet_found} containers")
            if dotnet_found > 0:
                print(f"        âœ“ cgroup v2 compatible: {dotnet_compat}")
                print(f"        âœ— cgroup v2 incompatible: {dotnet_incompat}")
        
        print(f"\n   Output file: {csv_path}")
        
        if args.verbose:
            print("\nðŸ“‹ Top 10 most used images:")
            top_images = df['image_name'].value_counts().head(10)
            for img, count in top_images.items():
                print(f"   {count:4d} Ã— {img}")
        
    except Exception as e:
        print(f"\nâœ— Error during collection: {e}")
        if log_to_file:
            logger.error(f"Error during collection: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
            if log_to_file:
                logger.exception("Full traceback:")
        return 1
    
    finally:
        # Disconnect
        client.disconnect()
        if log_to_file:
            logger.info("Disconnected from OpenShift cluster")
    
    if log_to_file:
        logger.info("=" * 60)
        logger.info("image-cgroupsv2-inspector completed successfully")
        logger.info("=" * 60)
    
    print("\nâœ“ Done!")
    return 0


if __name__ == "__main__":
    sys.exit(main())

